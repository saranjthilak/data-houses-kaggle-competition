{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:20:18.725515Z",
     "iopub.status.busy": "2025-05-13T09:20:18.725244Z",
     "iopub.status.idle": "2025-05-13T09:20:21.807618Z",
     "shell.execute_reply": "2025-05-13T09:20:21.806783Z",
     "shell.execute_reply.started": "2025-05-13T09:20:18.725494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell to regroup all your imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display = 'diagram')\n",
    "\n",
    "# Sklearn preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.ensemble import AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor, StackingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_regression, VarianceThreshold, SelectFromModel\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÜ Le Wagon Kaggle Batch Challenge\n",
    "\n",
    "**Welcome to your first Kaggle competition!**\n",
    "\n",
    "<img src='https://wagon-public-datasets.s3.amazonaws.com/data-science-images/ML/kaggle-batch-challenge.png' width=600>\n",
    "\n",
    "Your objective is to **submit an answer (online)** to the open competition [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) üè†\n",
    "\n",
    "Fortunately, you have already come across the housing dataset earlier in the bootcamp! You will be semi-guided toward a **baseline model**, and only after creating a baseline will you be free to improve and refine it. We will approach the problem using **pipelines** (the best practice)!\n",
    "\n",
    "A few words on Kaggle:\n",
    "- Kaggle will rank your submission amongst all participants!\n",
    "- Everyone is removed from the public leaderboard after 2 months\n",
    "- You can make up to 10 submissions per day\n",
    "\n",
    "üßπ Today is the perfect day to practice keeping your long notebook **tidy** üßπ\n",
    "- Collapse all headings from the command palette (`Cmd + Shift + P`)\n",
    "- Stay  \"idempotent\" (`Restart & Run All` should never crash)\n",
    "- Name and delete variables carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Setup\n",
    "\n",
    "üëâ Create an account on Kaggle if you want to participate in the competition\n",
    "\n",
    "üëâ Join the [House Prices Challenge](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) \n",
    "\n",
    "üëâ Write down your Kaggle `username` in the [results spreadsheet here](https://docs.google.com/spreadsheets/d/1ZEBKwa_k1Ytb0WCOh-Nopq3eaezwBNu1SAqKXEXRguc/edit#gid=0); if you can't find your batch, reach out to your teacher!\n",
    "\n",
    "**The whole batch will compete as a group against the team of TAs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "In the challenge instructions, you should have already executed the steps to download everything you need from Kaggle into your current notebook folder:\n",
    "\n",
    "- `train.csv` is your `(1460, 81)` training set containing `X` and `y`\n",
    "- `test.csv` is your `(1459, 80)` testing set without the associated target `y` üòà\n",
    "- `sample_submission.csv` describes the format required to submit your answer\n",
    "\n",
    "‚ÑπÔ∏è You'll find a detailed description of the dataset [here](https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/07-Ensemble-Methods/kaggle_houses_data_description.txt). Refer to it throughout the challenge!\n",
    "\n",
    "Your goal is to predict the `y_pred` missing from your test set and submit it to discover your `test_score` and ranking\n",
    "\n",
    "‚ùì Load the training dataset into a DataFrame called `data`, and create your `X` and `y`. Inspect their shapes.\n",
    "\n",
    "**Hint:** if you check the CSV file, you will notice a column called `Id`. When reading the CSV file into a DF, make sure to set `index_col=\"Id\"` so that you don't get two ID columns üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:34:45.704917Z",
     "iopub.status.busy": "2025-05-13T09:34:45.704602Z",
     "iopub.status.idle": "2025-05-13T09:34:45.727967Z",
     "shell.execute_reply": "2025-05-13T09:34:45.727020Z",
     "shell.execute_reply.started": "2025-05-13T09:34:45.704893Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\", index_col=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:34:48.459529Z",
     "iopub.status.busy": "2025-05-13T09:34:48.459233Z",
     "iopub.status.idle": "2025-05-13T09:34:48.477201Z",
     "shell.execute_reply": "2025-05-13T09:34:48.476115Z",
     "shell.execute_reply.started": "2025-05-13T09:34:48.459506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4           70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "Id                                  ...                                     \n",
       "1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "3          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "4          Lvl    AllPub    Corner  ...        0    NaN   NaN         NaN   \n",
       "5          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                             \n",
       "1        0      2    2008        WD         Normal     208500  \n",
       "2        0      5    2007        WD         Normal     181500  \n",
       "3        0      9    2008        WD         Normal     223500  \n",
       "4        0      2    2006        WD        Abnorml     140000  \n",
       "5        0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:35:07.669309Z",
     "iopub.status.busy": "2025-05-13T09:35:07.669048Z",
     "iopub.status.idle": "2025-05-13T09:35:07.676408Z",
     "shell.execute_reply": "2025-05-13T09:35:07.675511Z",
     "shell.execute_reply.started": "2025-05-13T09:35:07.669289Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=\"SalePrice\")\n",
    "y = data[\"SalePrice\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:35:09.511948Z",
     "iopub.status.busy": "2025-05-13T09:35:09.511603Z",
     "iopub.status.idle": "2025-05-13T09:35:09.517310Z",
     "shell.execute_reply": "2025-05-13T09:35:09.516297Z",
     "shell.execute_reply.started": "2025-05-13T09:35:09.511921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1460, 79)\n",
      "Shape of y: (1460,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üê£ 1. BASELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Initial feature overview\n",
    "\n",
    "79 features are too much to deal with one by one for a first baseline pipeline! Let's treat them solely based on their `dtype`:\n",
    "\n",
    "‚ùì How many numerical features vs. categorical features do we have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:37:53.070268Z",
     "iopub.status.busy": "2025-05-13T09:37:53.069332Z",
     "iopub.status.idle": "2025-05-13T09:37:53.078662Z",
     "shell.execute_reply": "2025-05-13T09:37:53.077604Z",
     "shell.execute_reply.started": "2025-05-13T09:37:53.070209Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 36\n",
      "Number of categorical features: 43\n"
     ]
    }
   ],
   "source": [
    "# Exclude the target column 'SalePrice' from the feature set\n",
    "numerical_features = data.select_dtypes(include=[\"number\"]).drop(columns=\"SalePrice\")\n",
    "categorical_features = data.select_dtypes(include=[\"object\", \"category\"])\n",
    "\n",
    "# Count the number of features\n",
    "num_numerical = numerical_features.shape[1]\n",
    "num_categorical = categorical_features.shape[1]\n",
    "\n",
    "print(\"Number of numerical features:\", num_numerical)\n",
    "print(\"Number of categorical features:\", num_categorical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a Series called `feat_categorical_nunique` containing the number of **unique values** for each categorical feature in our training set. How many unique categories are there in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:41:16.712751Z",
     "iopub.status.busy": "2025-05-13T09:41:16.712425Z",
     "iopub.status.idle": "2025-05-13T09:41:16.728264Z",
     "shell.execute_reply": "2025-05-13T09:41:16.727197Z",
     "shell.execute_reply.started": "2025-05-13T09:41:16.712730Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values per categorical feature:\n",
      " MSZoning          5\n",
      "Street            2\n",
      "Alley             2\n",
      "LotShape          4\n",
      "LandContour       4\n",
      "Utilities         2\n",
      "LotConfig         5\n",
      "LandSlope         3\n",
      "Neighborhood     25\n",
      "Condition1        9\n",
      "Condition2        8\n",
      "BldgType          5\n",
      "HouseStyle        8\n",
      "RoofStyle         6\n",
      "RoofMatl          8\n",
      "Exterior1st      15\n",
      "Exterior2nd      16\n",
      "MasVnrType        3\n",
      "ExterQual         4\n",
      "ExterCond         5\n",
      "Foundation        6\n",
      "BsmtQual          4\n",
      "BsmtCond          4\n",
      "BsmtExposure      4\n",
      "BsmtFinType1      6\n",
      "BsmtFinType2      6\n",
      "Heating           6\n",
      "HeatingQC         5\n",
      "CentralAir        2\n",
      "Electrical        5\n",
      "KitchenQual       4\n",
      "Functional        7\n",
      "FireplaceQu       5\n",
      "GarageType        6\n",
      "GarageFinish      3\n",
      "GarageQual        5\n",
      "GarageCond        5\n",
      "PavedDrive        3\n",
      "PoolQC            3\n",
      "Fence             4\n",
      "MiscFeature       4\n",
      "SaleType          9\n",
      "SaleCondition     6\n",
      "dtype: int64\n",
      "\n",
      "Total number of unique categories: 251\n"
     ]
    }
   ],
   "source": [
    "# Create the Series with number of unique values per feature\n",
    "feat_categorical_nunique = categorical_features.nunique()\n",
    "\n",
    "# Total number of unique categories across all categorical features\n",
    "total_unique_categories = feat_categorical_nunique.sum()\n",
    "\n",
    "print(\"Unique values per categorical feature:\\n\", feat_categorical_nunique)\n",
    "print(\"\\nTotal number of unique categories:\", total_unique_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î If we were to `OneHotEncode` all categorical features, our feature matrix `X_preproc` would become pretty big and sparse, with almost 300 (highly correlated) features for only 1400 observations. Ideally, we should aim at feeding our model with a maximum of ~50 features (üìö read this [rule of thumb](https://datascience.stackexchange.com/a/11480/98300))\n",
    "\n",
    "We know 2 main strategies to reduce the number of categorical features post-preprocessing:\n",
    "1. **[Remove](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)** features that bring too little explanation to our model; this may require statistical analysis of feature importance\n",
    "2. **[Ordinally encode](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)** (instead of one-hot encode) categorical features into integers; this, however, creates a notion of \"order\" (1 > 2 > 3 > ...) that can be detrimental if not handled properly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the **histogram** of the number of unique values per categorical feature. Do you see some quick wins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:46:43.340461Z",
     "iopub.status.busy": "2025-05-13T09:46:43.339868Z",
     "iopub.status.idle": "2025-05-13T09:46:43.554576Z",
     "shell.execute_reply": "2025-05-13T09:46:43.552782Z",
     "shell.execute_reply.started": "2025-05-13T09:46:43.340435Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the histogram\n",
    "plt.figure(figsize=(6, 4))\n",
    "feat_categorical_nunique.hist(bins=20, edgecolor='black')\n",
    "plt.title(\"Histogram of Unique Values per Categorical Feature\")\n",
    "plt.xlabel(\"Number of Unique Categories\")\n",
    "plt.ylabel(\"Number of Features\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As a starting point, what about simply **removing** all features that have **7 unique values or more**, and one-hot encoding the rest? Let's keep ordinal encoding and statistical feature selection for the next iteration of our pipeline.\n",
    "\n",
    "‚ùì Store the names of the features to be OHE'd in a list called `feat_categorical_small` below. How many features will be OHE'd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:51:51.811318Z",
     "iopub.status.busy": "2025-05-13T09:51:51.810882Z",
     "iopub.status.idle": "2025-05-13T09:51:51.818195Z",
     "shell.execute_reply": "2025-05-13T09:51:51.817227Z",
     "shell.execute_reply.started": "2025-05-13T09:51:51.811296Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to one-hot encode: 34\n",
      "Features to OHE:\n",
      " ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'BldgType', 'RoofStyle', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "# Filter features with fewer than 7 unique values\n",
    "feat_categorical_small = feat_categorical_nunique[feat_categorical_nunique < 7].index.tolist()\n",
    "\n",
    "# Output the result\n",
    "print(\"Number of features to one-hot encode:\", len(feat_categorical_small))\n",
    "print(\"Features to OHE:\\n\", feat_categorical_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:52:02.538420Z",
     "iopub.status.busy": "2025-05-13T09:52:02.538161Z",
     "iopub.status.idle": "2025-05-13T09:52:02.543625Z",
     "shell.execute_reply": "2025-05-13T09:52:02.542234Z",
     "shell.execute_reply.started": "2025-05-13T09:52:02.538401Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code below (and clear the cell once it passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T09:52:03.368051Z",
     "iopub.status.busy": "2025-05-13T09:52:03.367547Z",
     "iopub.status.idle": "2025-05-13T09:52:04.092485Z",
     "shell.execute_reply": "2025-05-13T09:52:04.091655Z",
     "shell.execute_reply.started": "2025-05-13T09:52:03.368013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/saranjthilak92/code/saranjthilak/05-ML/07-Ensemble-Methods/data-houses-kaggle-competition/tests\n",
      "plugins: typeguard-4.4.2, anyio-4.8.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_features_overview.py::TestFeaturesOverview::test_feat_categorical_small \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/features_overview.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed features_overview step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'features_overview',\n",
    "    n=len(feat_categorical_small)\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Baseline Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Preprocessing\n",
    "\n",
    "‚ùì Let's code the basic preprocessing pipeline described below. Save it under `preproc_baseline`.\n",
    "\n",
    "For categorical features:\n",
    "- Simple-Impute with the most frequent values\n",
    "- One-Hot Encode features that have less than 7 unique values to start with\n",
    "- Drop all other features\n",
    "\n",
    "\n",
    "As for numerical features:\n",
    "- Simple-Impute with strategy `mean`\n",
    "- Min-Max Scale\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>‚ÑπÔ∏è Click here for a pro tip</summary>\n",
    "\n",
    "If you are confident, you can try Sklearn's shorter-syntax `make_pipeline` or `make_column_transformer` instead of the longer syntax of `Pipeline` or `ColumnTransformer`; also useful if you want to avoid giving names manually to every step.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Look at the **shape** of your preprocessed DataFrame and save it to `shape_preproc_baseline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'preproc_baseline',\n",
    "    shape=shape_preproc_baseline\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Add Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Add a simple Decision Tree model to your `preproc_baseline` and store it to `pipe_baseline` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Cross-Validate\n",
    "\n",
    "‚ùì Read the Kaggle [contest evaluation rules](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation). Which performance metric do you need? Is it readily available in Sklearn?\n",
    "\n",
    "Sadly, it isn't! We will need to create our custom `sklearn.metrics.scorer` object to pass to any cross-validation or Grid Search. The process is described below:\n",
    "\n",
    "\n",
    "1. Create a scorer called `rmsle` using [`make_scorer`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) that can be passed as a value for the `scoring` `kwarg` like so:  \n",
    "    ```python\n",
    "    cross_val_score(pipe_baseline, X, y, cv=5, scoring=rmsle)\n",
    "    ```\n",
    "2.  Create its negative counterpart, `rmsle_neg`, which is best when _maximized_; this will come in handy later as `GridSearchCV` always tries to _maximize_ a score üòâ\n",
    "    ```python\n",
    "    GridSearchCV(pipe_baseline, param_grid=..., cv=5, scoring=rmsle_neg)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSLE formula\n",
    "\n",
    "$$\\text{RMSLE}(y, \\hat{y}) = \\sqrt{\\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (\\log_e (1 + y_i) - \\log_e (1 + \\hat{y}_i) )^2.}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì5-fold cross-validate your `pipe_baseline` using this metric to get a first glance at your baseline performance.    \n",
    "\n",
    "Store your mean score as `score_baseline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Predict Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Predict `y_pred_baseline` from the Kaggle `test.csv` dataset you stored in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n",
    "X_test_ids = X_test['Id'] # Keep ids\n",
    "X_test = X_test.drop(columns=['Id'])\n",
    "\n",
    "# Predict y_pred_baseline\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Finally, store your ready-to-submit CSV as `submission_baseline.csv` in the `data` folder. **Carefully read** and understand Kaggle's required format and test it below (you don't need to submit this baseline to Kaggle for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([X_test_ids, pd.Series(y_pred_baseline, name=\"SalePrice\")], axis=1)\n",
    "results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Kaggle format submission in the `data` folder\n",
    "results.to_csv(\"data/submission_baseline.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "tmp = pd.read_csv(\"data/submission_baseline.csv\")\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'submission_baseline',\n",
    "    score_baseline = score_baseline,\n",
    "    submission_shape = tmp.shape,\n",
    "    submission_columns = list(tmp.columns),\n",
    "    submission_dtypes = str(list(tmp.dtypes)),\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèãÔ∏è‚Äç‚ôÄÔ∏è 2. ITERATIONS \n",
    "\n",
    "üéâ üéâ Congratulation on having fully pipelined a baseline model! You will see now how much easier it is to iterate and improve performance üöÄ\n",
    "\n",
    "Now, your goal is to improve your prediction and submit it to Kaggle **at least 30 minutes before the Recap ‚è≥**\n",
    "\n",
    "We have some suggestions for improvements below: **pick your battles** and **incrementally** improve your pipeline as you see fit!\n",
    "\n",
    "**Estimators**\n",
    "\n",
    "- Tree-based ensembles (a must-try today); probably the best suited for problems with many categorical features\n",
    "- Stacking!\n",
    "- XGBoost!\n",
    "\n",
    "**Preprocessing** (once your first ensemble model works)\n",
    "\n",
    "- **Ordinal Encoding** of categorical features with a hidden notion of order in their values (e.g. \"bad\", \"average\", good\")\n",
    "- **Statistical Feature Selection** to remove useless features (avoids overfitting and reduces training time)\n",
    "- Predict `log(SalePrice)` instead?\n",
    "- ü§∑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocessing Iteration ‚ô≤ \n",
    "**‚ö†Ô∏è Come back here only after you have iterated on your estimators in section 2.2 ‚ö†Ô∏è**\n",
    "\n",
    "‚è© Collapse me if I'm not in use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Ordinal Encoding (~1h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Look at the following feature. Couldn't it be encoded numerically in a wise manner?\n",
    "```\n",
    "ExterQual: Evaluates the quality of the material on the exterior \n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "```\n",
    "\n",
    "üí° Luckily, the `OrdinalEncoder` and its argument `categories`  allows us to do just that! Check it out below and make sure to understand how this works üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specific order for features\n",
    "# Note: if you change this order, it will change the output for .transform()\n",
    "feature_A_sorted_values = ['bad', 'average', 'good']\n",
    "feature_B_sorted_values = ['dirty', 'clean', 'new']\n",
    "\n",
    "encoder = OrdinalEncoder(\n",
    "    categories=[\n",
    "        feature_A_sorted_values,\n",
    "        feature_B_sorted_values\n",
    "    ],\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "\n",
    "# Just some random training data\n",
    "XX = [\n",
    "    ['good', 'dirty'],\n",
    "    ['bad', 'new'],\n",
    "    ['average', 'clean'],\n",
    "]\n",
    "\n",
    "encoder.fit(XX)\n",
    "\n",
    "encoder.transform([\n",
    "        ['bad', \"dirty\"],\n",
    "        [\"average\", \"clean\"],\n",
    "        ['good', 'new'],\n",
    "        ['bad', 'oops never seen this label before']\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Your turn**: split your categorical preprocessor into\n",
    "\n",
    "- `preproc_ordinal` to ordinally encode **some features** (of your choice)\n",
    "- `preproc_nominal` to one-hot encode the other ones\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "- You won't be able to avoid hard-coding names and ordered values of features! Be tidy!\n",
    "- It's a good practice to sort your features alphabetically to avoid bad surprises\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Statistical Feature Selection (~30min)\n",
    "\n",
    "Our goal is to remove the least interesting features to limit overfitting and shorten training time.  \n",
    "\n",
    "üî• We will make use of Sklearn's [feature selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) transformers directly in your pipeline!\n",
    "\n",
    "‚ùóÔ∏è We recommend you try **only Option 1 today**, to start with. Options 2 and 3 will be corrected in the Recap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 (Recommended) - <font color=green>Univariate</font> Feature Selection\n",
    "*based on their mutual information with target `y`*\n",
    "\n",
    "- Feel free to add a `SelectPercentile` filter at the end of your `preproc` pipeline.\n",
    "- This will filter out features that, taken individually, least explain your target!\n",
    "- The statistical test we recommend passing to SelectPercentile is the `mutual_info_regression`\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>ü§î What is mutual information? Click here!</summary>\n",
    "\n",
    "- [Mutual Information](https://en.wikipedia.org/wiki/Mutual_information) is a **statistical** distance between two probability distributions\n",
    "- Correlation is a **linear** distance between two random variables\n",
    "- Mutual Information is more general and measures the reduction of uncertainty in Y after observing X.\n",
    "- On the other hand, if you already know you are working with variables that are smooth (like continuous numerical variables), sometimes correlation may tell you more about them, for instance if their relationship is monotonic.\n",
    "\n",
    "See [this animation](https://twitter.com/ari_seff/status/1409296508634152964)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - <font color=green>Multivariate</font> Feature Selection\n",
    "*based on their combined relationship with target `y`*\n",
    "\n",
    "ü§î We want to remove features that do not help predict our target even when combined with all the others.\n",
    "\n",
    "1Ô∏è‚É£ To do so, remember that we can use the [`permutation_importance`](https://scikit-learn.org/stable/modules/permutation_importance.html) metric in combination with an estimator! It trains one pipe per feature to estimate which feature makes our performance score *decrease* the most when shuffling it randomly. These would be our most important features, which we don't want to remove.\n",
    "\n",
    "The best thing is that `scikit-learn` allows you to integrate this methodology directly into your `preproc` pipeline thanks to the [`SequentialFeatureSelector`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html) transformer; this will recursively remove the least important features according to the `cross_val_score`.\n",
    "\n",
    "When you have many features, however, this process can take extremely long to train.\n",
    "\n",
    "2Ô∏è‚É£ Alternatively, a faster way would be to make use of models that already output some measure of `feature_importance` when being fitted. For instance, trees with a Gini-based `feature_importance_`, or Lasso regressions with an L1 `coef_`. `scikit-learn` already has the [`SelectFromModel`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html) transformer to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3 - <font color=green>Unsupervised</font> Selection?\n",
    "*filter based only on the properties of `X`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì A quick win is to remove features with the lowest variance. Think about it: a feature that only has one value is useless (and has a variance of 0).\n",
    "\n",
    "Feel free to add a [`VarianceThreshold`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) to the end of your pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Additionally, we can check for correlation between our **numerical features** only\n",
    "\n",
    "- Use [Pearson's correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) combined with a heatmap to visually check whether any **numerical** features almost entirely correlate with others\n",
    "- Use `VIF` from `statsmodels` to check for features that have the highest multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì For **ordinal features**, we can use [Spearman's rank correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) instead to check whether some **ordinally encoded** features are almost entirely \"ordered\" similarly to others. Feel free to plot a heatmap again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Now, feel free to create a \"filter\" in your pipeline that removes any feature you want beyond a given (Spearman + Pearson) correlation threshold; you'll need a custom transformer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Treat Cyclical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì We have some time-based features, why not **transform them** into cyclical features?\n",
    "\n",
    "üîé If you want to know more about why and how we do this, go back to the `Preprocessing Workflow` challenge of the `Prepare the dataset` unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Target Engineering (~15min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì We are asked to minimize the RMS**L**E. Why don't we transform our target to directly predict its `log`?\n",
    "- Check out the histogram of the target `y`\n",
    "- Normally distributed variables should be easier to predict with linear or parametric models\n",
    "- Create `y_log` and your new performance metrics\n",
    "- Don't forget to take the exponent of your predictions at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Model Iteration ‚ôª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Final Version of the Preproc Pipeline\n",
    "‚ùìWe advise you to start with a fresh definition of your preprocessing pipeline below. Copy-paste from your existing code above.\n",
    "\n",
    "This way you can quickly update it as needed and then try many model types to find the best one possible. You can try GridSearch (this could take a lot of time) or go model by model.\n",
    "\n",
    "You can try one or more of the different models you learned in the previous units, and today. \n",
    "\n",
    "üëâ Your goals:\n",
    "\n",
    "  - **Try at least one linear model**\n",
    "  \n",
    "  - **Try at least one of the tree-based models** you discovered in this unit.\n",
    "\n",
    "  - Compare the **cross-validated** scores of your different models.\n",
    "\n",
    "  - It's also interesting to **compare how long it takes** to cross-validate the different models. üîé Add the `%%time` magic command as the first line of a notebook cell to time the execution of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÖFINAL SUBMISSION (submit at least 30 min before Recap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to discover your real test score by submitting to Kaggle! \n",
    "\n",
    "üëâ Follow and complete the next steps to see how good your model is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n",
    "\n",
    "X_test_ids = X_test['Id'] # Keep ids\n",
    "X_test = X_test.drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the optional cyclical feature treatment in 2.1, you will need to run the following cell to add the extra columns before you feed X_test into your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, add cyclical feature columns to X_test like we did to X\n",
    "if 'months_in_a_year' in locals():\n",
    "    # months_in_a_year is defined, so we need to add the cyclical features\n",
    "    X_test['sin_MoSold'] = np.sin(2 * np.pi * (X_test.MoSold - 1) / months_in_a_year)\n",
    "    X_test['cos_MoSold'] = np.cos(2 * np.pi * (X_test.MoSold - 1) / months_in_a_year)\n",
    "\n",
    "    X_test.drop(columns=['MoSold'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Predict using your best estimator, and store the results in `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Run the following cells to prepare your predictions to submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame in the correct format\n",
    "results = pd.concat([X_test_ids, pd.Series(predictions, name=\"SalePrice\")], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Kaggle format submission\n",
    "results.to_csv(\"submission_final.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Go to Kaggle and submit your predictions. What is your test score? Compare it to the validation scores you obtained.\n",
    "\n",
    "üëâ Write down your test score on the [result spreadsheet here](https://docs.google.com/spreadsheets/d/1ZEBKwa_k1Ytb0WCOh-Nopq3eaezwBNu1SAqKXEXRguc/edit#gid=0) (pick the correct batch!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
